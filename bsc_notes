Notizen:

1. Zunächst einmal stellte sich die Herausforderungen, alle Module eines Frameworks zu erfassen. Gängige Python-Methoden geben zwar die Submodule aus, aber um sämtliche Konfiguratonsoptionen zu finden, müssen die auch noch durchlaufen werden. Hier war die Schwierigkeit einen Überblick zu behalten, da manche Methoden direkt aurufbar waren bspw. mflow.get_tracking_uri, die jedoch über den Pfad.
2. Rausgefiltert werden dabei Methods mit single leading underscore _ (Name ist nur für interne Zwecke) und double leading underscore __ (wird genamemangled also textuell mit etwas anderem ersetzt) siehe https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-single-and-double-underscore-before-an-object-name
3. Problematisch sind ebenfalls die Dopplungen von Namen, so befindet sich bspw.
	get_tracking_uri in mlflow und in mlflow.tracking
	log_artifact in mlflow und mlflow.tracking.MlflowClient
4. offen ist zudem wie die Config Optionen aus 3. in den echten Projekten dann auch getracket werden sollen. Möglichkeit: import mlflow und from mlflow Zeile untersuchen und dies zum Standard der Suche machen
5. Schwierigkeit zudem wie ich die Config-Options von normalen Methoden unterscheiden. list_artifacts ist vermutlich keine Configuration Option.
6. Was ist zu dem mit den anderen dictioniairies etc.
7. Liste aller Methoden und Klassen mit for-Schleifen erwies sich als nicht zielführend, da Tiefe der for-Schleifen unbekannt -> Lösung: Baumstruktur mit Rekursion
8. Problem: Methoden können auf mehreren Wegen erreicht werden z.B. mlflow.h2o.mlflow.h2o.mlflow -> Gefahr von endlosen Schleifen / Rekursion
    Lösung: bei jedem Element wird geprüft ob es schon bereits im Baum vorhanden ist -> Verhindert Dopplungen, jedoch sind die Elemente dann an "falschen" Zweigen zugeordnet


types:
- module
- type
- method
- property
- builtin_function_or_method
- NoneType
- function
- str
- int
- string._TemplateMetaclass
- logging._StderrHandler
- bool
- logging.RootLogger
- urllib3.util.retry._RetryMeta
- typing._GenericAlias
- dict
- re.Pattern
- method_descriptor
- float
- getset_descriptor
- method_descriptor
- yaml.YAMLObjectMetaclass
- list

- Lösung:
    Doku der Packages werden auf der Website durchsucht. Dafür wird beautfilsoup als Scraper verwendet.
    Das ganze wird an PyTorch getestet. Dabei werden zunächst die ganzen Links der einzelnen Module gescrapt.
    In einer for-Schleife werden diese Links durchlaufen und in einem nested Dictionairy gespeichert mit dem Aufbau (module, (Function, Beschreibung))
    Vorteil ist das man auf Basis der Beschreibungen der Funktion sehr gut erkennen kann, welche Funktionen was machen. Beschreibungen die mit "Return" oder "" anfangen, kann man direkt aussortieren, Beschreibungen die mit Set anfangen sind potentielle Optionen.
    PRoblem: Die Beschreibungen werden tabellarisch in der Doku gespeichert. Leider sind nicht alle Seiten gleich aufgebaut, sodass bei einigen Modulen nichts gefunden wird oder die falsche Tabelle ausgelesen wird. Das muss händisch noch überprüft werden

- Neuer Ansatz: einfach dir() über Torch laufen lassen. Damit kann alles was über torch. aufgerufen wird angezeigt werden.


- Statische Code Analyse (https://luminousmen.com/post/python-static-analysis-tools)

- Zu Berücksichtigen:
    - Kommentare mit # oder "" ausschließen!
    - mehrere Zeilen zurückgeben, wenn über mehrere Zeilen verläuft
    - import Zeile besondere Aufmerksamkeit schenken. Mögliche Fälle: 1. import tensorflow 2. import tensorflow as tf 3. from tensorflow import xx
        1. Fall - Möglichkeiten:
            import tensorflow
            import tensorflow as tf
            import tensorflow, xx
            import tensorflow as tf, xx
            import xx, tensorflow
            import xx, tensorflow as tf
            import xx, tensorflow, yy
            import xx, tensorflow as tf, yy
            Lösung: unterteilen in mehrere Strings: import rauscutten
            UPDATE: 1. Fall: Falls Klassen definiert werden, an dieser Stelle direkt rausfiltern
            UPDATE: sklearn.base enthält as deshalb ändern
            evtl. Test mit allen möglichen Konstellationen schreiben?!

- UPDATE: nur noch Klassen rausfiltern. Klassen werden groß geschrieben, und von den Klassen nur noch die Parameter
        möglich Parameter kann man mit clf.__dict__ ausgeben, wenn man die Attribute, die mit _ enden noch löscht

- search_words ausdünnen, damit nicht jedes Mal eine spezifische Methode gesucht wird -> direkt eliminieren?

- Problem from sklearn import Class123 as c
    -> wie kann man nun nach c schauen?
Möglichkeiten wie Klassen auftachen:
    1. (Klasse,
    1. (Klasse)
    1. (Klasse
    1. (Klasse(
    1. (Klasse.
    2. ,Klasse)
    2. ,Klasse
    2. ,Klasse(
    2. ,Klasse,
    2. ,Klasse.
    3.  Klasse
    3.  Klasse(
    3.  Klasse,
    3.  Klasse)
    3.  Klasse.
    4. .Klasse(
    4. .Klasse)
    4. .Klasse,
    4. .Klasse
    4. .Klasse.


https://stackoverflow.com/questions/33506902/python-extracting-editing-all-constants-involved-in-a-function-via-ast

ungeklärte Probleme:
    - was wenn sich Wert einer Variable ändert bspw. am Anfang a = 5, am Ende a = 10, ausgegeben wird nur a = 10

zutun:
    - BinOp und UnaryOp immer checken!!!
    - Listen können unendlich tief sein -> auch das abdecken!

Fragen:
    - sklearn.cluster.AffinityPropagation() irrelevant?
    - ap = sklearn.cluster.AffinityPropagation() relevant?
    - linear_model.LinearRegression(2, 5) --> was davon relevant
    - regr = linear_model.LinearRegression(2, 5)
    - regr.fit(diabetes_X_train, diabetes_y_train)

- Ursprünglich alles als Dicitionary gespeichert, jedoch alphabetische Sortierung und keys einmalig, daher Lieber Liste
- Problem: unterscheiden zwischen strings und variable: plt.scatter(diabetes_X_test, diabetes_y_test, color=black)

Relevant:
    - linear_model.LinearRegression(6, 10)
    - regr = linear_model.LinearRegression(2, 5)
    - mdl.append(SVC(class_weight=None, probability=True))

irrelevant:
    - regr.fit(diabetes_X_train, diabetes_y_train)
    - regr2 = regr

Offen:
    - def func1():
        count = 100
        return count

      count = func1()
      linear_model.LinearRegression(count)
    - Welche Datenstruktur?
    - Wie berücksichtige ich die Struktur?
        - if/else, for
        - with
        - Funktionen
        - Klassen

große Frage: wie mit Klassen und Funktionen umgehen?

To Do: Umgang mit Kontrollstrukturen if, else, for

Möglichkeit string in strings darzustellen:
    model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

limit: Klammern beim bin.op werden nicht mit übernommen bsp. accum = accum * rho + (grad**2) * (1 - rho)

Konsitenz reinbringen bei den Kontrollstrukturen: for, while wird gedruckt, if else nicht?!, try/except auch nicht?
    Mögliche Lösung: Zeilenangaben anhängen und zuordnen

line no function definitions


Struktur:
    1. Werte aus Import-Lines filtern
    2. Durch ast-Objekte iterieren und Objekte rauslesen, die Import-Werte enthalten
        Problem: bspw. Function, Class, For etc haben bodys und kapseln oft selbst nochmal eine Vielzahl an Objekten
        Loopen durch:
            FunctionDef body, decorater_list (unnötig)
            AsyncFunctionDef body, decorater_list (unnötig)
            ClassDef bases, keywords, body, decorater_list
            Delete targets
            Assign targets
            For body, orelse
            AsyncFor body, orelse
            While body, orelse
            If body, orelse
            With items, body
            Async With items, body
            Match cases
            Try body, handlers, orelse, finalbody
            Import names
            ImportFrom names
            Global names
            Nonlocal names

            BoolOp values
            Dict keys
            Set elts
            ListComp generators
            SetComp generators
            DictComp generators
            GeneratorExp generators
            Compare ops, comparators
            Call args, keywords
            JoinedStr values
            List elts
            Tuple elts

            comprehension ifs
            excepthandler ExceptHandler:body
            arguments posonlyargs, args, kwonlyargs, kw_defaults, defaults
            match_case body
            pattern


            Lösung: Typ prüfen und rausfiltern

            body: FunctionDef, AsyncFunctionDef, ClassDef, For, AsyncFor, While, If, With, AsyncWith, Try
            ?decorator_list: FunctionDef, AsyncFunctionDef, ClassDef
            orelse: For, AsyncFor, While, If, Try
            handlers: Try -> [excepthandler1: body] #Try hat handlers, handlers ist Liste aus mehrern ExceptHandlers, jeder ExceptHandler hat Body
            finalbody: Try

            Offen: Match

            3 Categorien:
            FunctionDef, AsyncFunctionDef, ClassDef, With, AsyncWith, ExceptHandler: body
            For, AsyncFor, While, If: body, orelse
            Try: body, orelse, handlers, finalbody


        Vorgehen:
            1. alle Objekte finden, in den relevante import-values auftauchen
            2. durch einzelene Objekte nach den 3 oberen Kategorieren iterieren
            3. gucken ob bei den import-values auch Klassen dabei sind (Vergleich mit scraper) attr =, id =


        category1 = [ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.With, ast.AsyncWith, ast.ExceptHandler]
category2 = [ast.For, ast.AsyncFor, ast.While, ast.If]
category3 = [ast.Import, ast.ImportFrom]

Frage: Wie umgehen wenn var = blabla + bla(LogisticRegression(x=1). Stand jetzt ist Var die Variable
umgang mit +=

code': "cross_val_predict(cv=KFold(2))"  -> Variable -> cv
code': 'kernels = [RBF(length_scale=0.1), fixed_kernel, '
            'RBF(length_scale=1.0, length_scale_bounds=(0.001, 1000.0)), '
            'C(1.0, (0.01, 100.0)) * RBF(length_scale=1.0, '
            'length_scale_bounds=(0.001, 1000.0))]'  -> Lösungen für mehrmals RBF?
kernels = [
    RBF(length_scale=2.0),
    RBF(length_scale_bounds=(0.5, 2.0)),
    ConstantKernel(constant_value=10.0),
    2.0 * RBF(length_scale=0.33, length_scale_bounds="fixed"),
    2.0 * RBF(length_scale=0.5),
    kernel_rbf_plus_white,
    2.0 * RBF(length_scale=[0.5, 2.0]),
    2.0 * Matern(length_scale=0.33, length_scale_bounds="fixed"),
    2.0 * Matern(length_scale=0.5, nu=0.5),
    2.0 * Matern(length_scale=1.5, nu=1.5),
    2.0 * Matern(length_scale=2.5, nu=2.5),
    2.0 * Matern(length_scale=[0.5, 2.0], nu=0.5),
    3.0 * Matern(length_scale=[2.0, 0.5], nu=1.5),
    4.0 * Matern(length_scale=[0.5, 0.5], nu=2.5),
    RationalQuadratic(length_scale=0.5, alpha=1.5),
    ExpSineSquared(length_scale=0.5, periodicity=1.5),
    DotProduct(sigma_0=2.0),
    DotProduct(sigma_0=2.0) ** 2,
    RBF(length_scale=[2.0]),
    Matern(length_scale=[2.0]),
]

Zu beachten: Dummys, Variablenzuweisung, AugAssing etc, decorators, Dopplungen

Speicherung in Tupel, da Dict sortiert sind

Zuweisung der Parameter zu den Klassen:
class sklearn.decomposition.SparseCoder(dictionary, *, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, split_sign=False, n_jobs=None, positive_code=False, transform_max_iter=1000)
alles was nach Sternchen kommt, muss mit Parameternamen angegeben werden
nur dictionary darf direkt mit einem Wert initialisiert werden
https://stackoverflow.com/questions/66922295/what-does-asterisk-mean-when-used-as-a-param-for-a-scikit-learn-model


(cfgnet-XNQxSlNA-py3.8) marco@Marcos-MacBook-Pro CfgNet % poetry run cfgnet export --output=export2 --format=png --include-unlinked --visualize-dot /Users/marco/repos/CfgNet

Scalpel wird nicht verwendet, da unter anderem Verarbeitung von Dictionairies nicht funktioniert. Bsp. x = test_dict["key"] läuft in Exception und führt zu Abbruch

Mögliches Vorgehen zum Tracking der Variablenwerte:
    1. Alle Variablenzuweisungen der Funktion rausfiltern
    2. Objekte nach gesuchten Variable durchsuchen

Zu Tun:
- Variablenwerte tracken
- Parameter im Fall von Dopplungen behandeln! -> DONE!!

Zu Variablenwerte tracken:
    1) Prüfen ob es sich um Variablen oder Konstanten handelt
    2) Wenn Variable(n), dann Übergeordnete Funktionen und Klassen betrachten:
        3) Alle oberen Zuweisungen rausfiltern
        4) Prüfen, welche Zuweisungen der(den) gesuchten Variable(n) Werte zuweisen
    -> Scope bleibt aber immer nur die übergeordnete Funktion / Klasse!

src  -> plugins -> source_code
-> modules: json file hinzufügen
-> von sklearn plug_in code mehr oder weniger kopieren bzw. die ersten beiden Funktionen der Klasse (is_responsible, parse_config_file
test -> files -> datei hinzufügen für pytorch zum testen

es muss ein git repository sein!
immer erst option zum artifact hinzufügen
artifact ist .py datei
plugin manager zeile 27, 47 adaptieren
unter plugin_manager bei source_code Plugins hinzuüfgen

diese beiden Befehle ausführen - .py datei in test/files ordner hinzufügen
poetry run cfgnet init /Users/marco/repos/CfgNet
poetry run cfgnet export --output=graph_test --format=png --include-unlinked --visualize-dot /Users/marco/repos/CfgNet



Scope fürs Variablentracking:
    - alle Assignments auf erster Ebene
        - dafür in obj_selector: alle Funktionen finden.

Variable.SaveSliceInfo fehlt irgendwie



torch: https://pytorch.org/docs/stable/tensors.html -> Klassen nochmal ansehen -> wenn empty, dann nicht hinzufügen?
torch: https://pytorch.org/docs/stable/tensor_attributes.html

2 mal gleicher Name für Klasse: was tun?
class
torch.profiler.profile(*, activities=None, schedule=None, on_trace_ready=None, record_shapes=False, profile_memory=False, with_stack=False, with_flops=False, with_modules=False, use_cuda=None)

class
torch.autograd.profiler.profile(enabled=True, *, use_cuda=False, record_shapes=False, with_flops=False, profile_memory=False, with_stack=False, with_modules=False, use_kineto=False, use_cpu=True)

handle of class variables: e.g. https://www.tensorflow.org/api_docs/python/tf/AggregationMethod


Datenfluss:
    - prüfen ob variable als Parameter übergeben wird
    - alle Variablenzuweisungen (auch aug und so) rausfiltern
    - alle übergeordnete Objekte der Variablen rausfiltern

Limits:
    - Aufrufe wie diesen (x_param() erkennt er nicht
    onehotencoder = OneHotEncoder(categorical_features=x_param())
    - augassign manuell nochmal jedes mal ändern
    - zu lang
    - with macht er gar nicht : dafür immer extra variable "with_python_as_p"

    xonstant progpagation auch mit erwähnrn und cfg

    krieterien:
        - Verwendung von KLassen
        - unbekannte parameter
        - code kann als ast geparst werden
        - gute bewertung
        - nicht zu viele klassen


     https://www.dunebook.com/opensource-tensorflow-projects/
     python3 main.py https://github.com/keras-team/keras tensorflow
     156/205 -> 657
     python3 main.py https://github.com/tensorpack/tensorpack tensorflow
     149/159 -> 120
     python3 main.py https://github.com/stellargraph/stellargraph tensorflow
     137/250 -> 71
     python3 main.py https://github.com/yahoo/TensorFlowOnSpark tensorflow
     142/200 -> 33
     python3 main.py https://github.com/tensorforce/tensorforce tensorflow
     22/34 -> 74
     python3 main.py https://github.com/tensorlayer/tensorlayer tensorflow
     222/260 -> 195
     python3 main.py https://github.com/google/prettytensor tensorflow
     python3 main.py https://github.com/google/prettytensor tensorflow
     45/78 -> 30

    https://www.libhunt.com/topic/pytorch
    python3 main.py https://github.com/CorentinJ/Real-Time-Voice-Cloning torch
    16/61 -> 20
    python3 main.py https://github.com/ultralytics/yolov5 torch
    28/61 -> 26
    python3 main.py https://github.com/yunjey/pytorch-tutorial torch
    46/110 -> 18
    python3 main.py https://github.com/babysor/MockingBird torch
    183/327 -> 80
    python3 main.py https://github.com/open-mmlab/mmdetection torch
    515/610 -> 557
    python3 main.py https://github.com/rwightman/pytorch-image-models torch
    641/1099 -> 171

    python3 main.py https://github.com/SeldonIO/MLServer mlflow
    30/30 -> 10

    python3 main.py https://github.com/awslabs/autogluon sklearn


\begin{table}[H]
\small
\begin{center}
\setlength{\tabcolsep}{5pt}
\begin{tabular}[h]{l|c c|c|c c|c|c c|c|c c|c} %p{7cm}
\hline
\multirow{3}{*}{ML-Projekt} & \multicolumn{3}{c|}{Klassen}      & \multicolumn{3}{c|}{Parameter}    & \multicolumn{6}{c}{variable Parameter}\\
                            & \multicolumn{3}{c|}{insgesamt}    & \multicolumn{3}{c|}{insgesamt}    & \multicolumn{3}{c|}{insgesamt}       & \multicolumn{3}{c}{Zuweisungen} \\
                            & M         & A     & \%            & M         & A     & \%            & M         & A     & \%                & M     & A     & \% \\
\hline \hline
Tensorforce                 & 55        & 55    & 100\%         & 105       & 105   & 100\%         & 58        & 58    & 100\%             & 96    & 76    & 79\% \\
RTVC                        & 86        & 86    & 100\%         & 165       & 165   & 100\%         & 78        & 78    & 100\%             & 83    & 80    & 96\% \\
AutoGluon                   & 65        & 65    & 100\%         & 98        & 98    & 100\%         & 32        & 32    & 100\%             & 19    & 19    & 100\% \\
MLServer                    & 30        & 30    & 100\%         & 57        & 57    & 100\%         & 11        & 11    & 100\%             & -     & -     & -\\
\hline
\end{tabular}
\caption{Ergebnisvergleich der manuellen Analyse (\textit{M}) mit dem Algorithmus (\textit{A})} \label{eval}
\end{center}
\end{table}





\section{Ermittlung der variablen Konfigurationswerte2}
Zunächst wird durch die Liste mit Dictionaries aus \ref{Parameters} iteriert.
Die Ermittlung der variablen Parameterwerte erfolgt über die Methode \textit{get\_parameter\_value()} der \textit{DataFlowAnalysis}-Klasse.
Beim Aufruf der Methode wird das Dictionary zusammen mit der Parametervariable \textit{n\_neighbors} übergeben.\\

Im ersten Schritt wird die Python-Datei als AST geparst.
Der resultierende Syntaxbaum wird traversiert und nach der Funktion gesucht, in der sich das Objekt befindet.
Dafür wird jeder erreichte Knoten auf seinen Typ geprüft.
Handelt es sich einen Knoten vom AST-Typ \textit{FunctionDef}, werden die Zeilennummern verglichen.
Befindet sich das Objekt innerhalb des Funktionskörpers, endet die Suche an dieser Stelle.
In Anschluss werden die Bestandteile der gefundenen Funktion, die erst nach der Parametervariablen aufgeführt werden, rausgefiltert.
Dafür wird durch die Liste an Objekten der Funktion iteriert und Objekte, dessen Zeilennummer größer als die Zeilennummer der Parametervariablen
ist, entfernt.\\

Für die Ermittlung möglicher Werte der Parametervariablen wird durch die gekürzte Liste mit den Funktionsobjekten iteriert, um
Zuweisungen zu finden.
Zu beachten ist, dass sich alle zu betrachtenden Funktionsobjekte auf der gleichen Ebene aufhalten.
Befinden sich im Körper der einzelnen Funktionsobjekten weitere Objekte, werden sie an dieser Stelle
nicht betrachtet.
Handelt es sich bei einem Objekt beispielsweise um eine Kontrollstruktur vom AST-Typ \textit{If}, könnte der Körper der
Kontrollstruktur Zuweisungen enthalten, die wir erst an späterer Stelle erfassen werden.
Wird bei einem Iterationsvorgang eine Zuweisung gefunden, die die gesuchte Parametervariable zum Ziel hat, wird der Wert in der
Variable \textit{temp\_variable\_value} zwischengespeichert.
Falls beim einem späteren Iterationsvorgang erneut ein Objekt gefunden wird, dass der gesuchten Variable einen Wert zuweist,
wird \textit{temp\_variable\_value} überschrieben, sodass am Ende nur der Variablenwert gespeichert wird, die der Parametervariablen am
nächsten ist.
Dies verhindert, dass Werte, die vor der Verwendung der Parametervariablen ohnehin überschrieben werden, als möglicher
Variablenwert in Frage kommen. \\

Falls kein möglicher Variablenwert gefunden wurde, wird zum einen der globale Namensraum nach Zuweisungen durchsucht und
zum anderen die Parameter in der Definition der Funktion überprüft.
Im ersten Vorgang lässt sich der Prozess der eben angesprochenen lokalen Zuweisungen übertragen.
Ist die Parametervariable in der Definition der Funktion vorhanden, müssen jedoch einige Besonderheiten bei der Behandlung der Argumente
berücksichtigt werden.
Die Parameter einer Funktion können fünf unterschiedliche AST-Typen besitzen: \textit{arg}, \textit{vararg}, \textit{kwonlyargs},
\textit{posonlyarg} oder \textit{kwarg}.
Ähnlich wie die Argumente bei \textit{ast.Call} müssen die AST-Typen unterschiedlich behandelt werden, damit die Parametervariable
beim Aufruf der Funktion eindeutig zugeordnet werden kann.
Im folgenden Codebeispiel werden die verschiedenen Typen mit ihrem Namen kenntlich gemacht: \\

\begin{lstlisting}[language=Python, frame=single, basicstyle=\small]
def func(posonlyarg1, posonlyarg2, /, arg1, arg2,
         arg3 = 1, *vararg, kwonlyarg1, kwonlyarg2, **kwarg):
    return

func("posonlyarg1", "posonlyarg2", arg2=2, *["arg1"],
     kwonlyarg1=1, kwonlyarg2=2, **{"arg3": 3, "new_arg": 0})
\end{lstlisting}
\

\textit{Positional-only arguments} sind Argumente, die vor der \textit{/}-Markierung stehen und dürfen nicht mit einem
Keyword-Argument übergeben werden.
\textit{Keyword-only arguments} sind das Gegenstück.
Sie müssen mit einem Keyword übergeben werden und befinden sich in der Definition immer nach \textit{varargs}.
\textit{Args} sind Argumente bei denen nicht festgelegt ist, ob sie mit einem Keyword übergeben werden.
Sie werden ansonsten ihrer Position nach zugeordnet.
Die Typen \textit{vararg} und \textit{kwarg} referenzieren die übergebenen \textit{*args}- und \textit{**kwargs}-Parameter,
die in \ref{Parameters} besprochen wurden.
Ist die Parametervariable in der Definition der Signatur aufgeführt, besteht die Möglichkeit, dass ihr wie bei \textit{arg3} ein Default-Wert
zugewiesen wird, der dementsprechend zur Liste möglicher Werte der Parametervariablen hinzugefügt werden muss.
Falls dem Parameter beim Aufruf der Funktion kein Wert zugewiesen wird, würde der Wert von \textit{arg3} im Beispiel ansonsten
\textit{3} betragen.\\

Im nächsten Schritt wird erneut durch die gekürzte Liste an Funktionsobjekten iteriert.
Dabei werden nur Objekte betrachtet, die, sofern vorhanden, nach der letzten Zuweisung eines Wertes an die
Parametervariable im Code auftreten.
Für jedes dieser Objekte wird der Syntaxbaum traversiert, um Zuweisungen, die sich verschachtelt im Körper eines Objektes
befinden, zu finden.
Dadurch können Zuweisungen gefunden werden, die sich zum Beispiel in Kontrollstrukturen wie \textit{if}- und \textit{else}-Zweigen,
in weiteren verschachtelten Funktionen oder auch in \textit{try}- und \textit{except}-Blöcken befinden.
Werden an dieser Stelle Zuweisungen für die gesuchte Parametervariable gefunden, werden sie der Liste möglicher Werte hinzugefügt. \\

Um die Suche nach möglichen Werten abzuschließen, werden, sofern die Parametervariable in der Definition der Funktion vorhanden ist,
in der gesamten Datei nach Aufrufen der Funktion durchsucht.
Dafür wird der Syntaxbaum des gesamten Codes der Python-Datei traversiert.
Für jeden Aufruf der Funktion wird je nach Argumenttyp und Position der gesuchten Parametervariable, der übergebene
Wert ausgelesen.
Handelt es sich einem übergebenen Wert erneut um eine Variable, wird der gesamte Prozess zur Ermittlung des Variablenwerts wiederholt. \\

Nach erfolgreichem Durchlauf gibt die \textit{get\_parameter\_value()}-Methode der \textit{DataFlowAnalysis}-Klasse
eine Liste mit möglichen Werten zurück.
Die Liste wird im Anschluss in ein Dictionary umgewandelt, dessen Schlüssel aufsteigende Zahlen sind.
Schlussendlich wird eine JSON-Datei erstellt, die alle gesuchten Konfigurationsoptionen des Git-Repositories enthält.
Für das gegebene Beispiel sieht der Eintrag wie folgt aus: \\

\begin{lstlisting}[frame=single, basicstyle=\small]
{'file': 'path/file.py',
 'class': 'sklearn.neighbors.KNeighborsRegressor',
 'parameter': {'n_neighbors': 'n_neighbors',
               'leaf_size': '25'}
 'variable parameters': {'n_neighbors': {'0': '6'}},
 'variable': 'knn',
 'line no': '4'}
\end{lstlisting}
\




\begin{table}[H]
\begin{center}
\begin{tabular}[h]{l|c|c|c|c}
\hline
Projekt         & Klassen   & Parameter & variable  & zuweisungen \\
\hline \hline
TensorForce     & 55        & 105       & 58        & 96\\
RTVC            & 86        & 165       & 78        & 83\\
AutoGluon       & 65        & 98        & 32        & 19\\
MLServer        & 30        & 57        & 11        & -\\
\hline
\end{tabular}
\caption{Manuelles Ergebnis} \label{manu}
\end{center}
\end{table}


\begin{table}[H]
\begin{center}
\begin{tabular}[h]{l|c|c|c|c|c|c|c|c}
\hline
Projekt         & Klassen   & \%    & Parameter & \%    & variable  & \%    & zuweisungen   & \% \\
\hline \hline
TensorForce     & 55        & 100\% & 105       & 100\% & 58        & 100\% & 76            & 79\% \\
RTVC            & 86        & 100\% & 165       & 100\% & 78        & 100\% & 80            & 96\% \\
AutoGluon       & 65        & 100\% & 98        & 100\% & 32        & 100\% & 19            & 100\% \\
MLServer        & 30        & 100\% & 57        & 100\% & 11        & 100\% & -             & - \\
\hline
\end{tabular}
\caption{Ergebnis vom Projekt} \label{algo}
\end{center}
\end{table}



\begin{table}[H]
\begin{center}
\begin{tabular}[h]{c|c|c|c|c}
\hline
ML-Bibliothek & TensorForce & RTVC & AutoGluon & MLServer \\
\hline \hline
ML-Klassen & 55 & 86 & 65 & 30\\
gefunden & 55 & 86 & 65 & 30  \\
\hline
Anteil & 100\% & 100\% & 100\% & 100\% \\
\hline
Parameter & 105 & 165 & 98 & 57 \\
gefunden & 105 & 165 & 98 & 57 \\
\hline
Anteil & 100\% & 100\% & 100\% & 100\%\\
\hline
variable Parameter & 58 & 78 & 32 & 11\\
Wertzuweisungen & 96 & 83 & 19 & - \\
gefunden & 76 & 80 & 19 & - \\
\hline
Anteil & 79\% & 96\% & 100\% & -\\
\hline
\end{tabular}
\caption{Evaluationsergebnis} \label{eval}
\end{center}
\end{table}


%\begin{table}[H]
%\begin{center}
%\begin{tabular}[h]{c|c|c|c|c|c}
%\hline
%Projekt & Version & ML-Bibliothek & ML-Klassen & Parameter & var. Parameter & Wertzuweisungen\\
%\hline \hline
%RTVC & 55 & 86 & 65 & 30\\
%AutoGluon & 55 & 86 & 65 & 30  \\
%\hline
%\end{tabular}
%\caption{Evaluationsergebnis} \label{eval}
%\end{center}
%\end{table}


02.06.
- mehr strukturieren mit eigenen Abschnitt für die Analysen
- Das Vererbung nicht erkannt wird mit reinnehmen
- Typen der Parameter kategorisieren
- Begrenzung: Decorators bei Variablenwert analyse
- Klassen die innerhalb eines Dicitioamrys haben falsche Zeilennummer

python3 main.py https://github.com/ShusenTang/Dive-into-DL-PyTorch torch
39
python3 main.py https://github.com/lukemelas/EfficientNet-PyTorch torch
38
python3 main.py https://github.com/eriklindernoren/PyTorch-YOLOv3 torch
27
python3 main.py https://github.com/facebookresearch/PyTorch-BigGraph torch
47
python3 main.py https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection torch
47
python3 main.py https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning torch
26
python3 main.py https://github.com/fepegar/torchio torch
30
python3 main.py https://github.com/vacancy/Synchronized-BatchNorm-PyTorch torch
13


python3 main.py https://github.com/nidhaloff/igel sklearn
12
python3 main.py https://github.com/scikit-learn-contrib/category_encoders sklearn
39
python3 main.py https://github.com/scikit-learn-contrib/sklearn-pandas sklearn
36
python3 main.py https://github.com/benedekrozemberczki/karateclub sklearn
7
python3 main.py https://github.com/kserve/kserve sklearn
21
python3 main.py https://github.com/nok/sklearn-porter sklearn
34


python3 main.py https://github.com/dennybritz/cnn-text-classification-tf tf
21

python3 main.py https://github.com/mozilla/DeepSpeech tf
34

python3 main.py https://github.com/thtrieu/darkflow tf
15

python3 main.py https://github.com/mljar/mljar-supervised sklearn
33

zeiten:
- Torch: 50 sekunden
- sklearn: 37 sekunden
- tf:


\indent In einer empirischen Studie über Konfigurationsfehler stellen \citeauthor{10.1145/2043556.2043572} fest,
dass in kommerziellen Softwareunternehmen für Speicherlösungen, knapp ein Drittel aller Ursachen von Kundenproblemen auf Konfigurationsfehler zurückzuführen sind.
Bei Konfigurationsfehlern sind Source Code und Eingabe zwar korrekt, es wird jedoch ein falscher Wert für eine Konfigurationsoption verwendet,
sodass sich die Software nicht wie gewünscht verhält.
Entwickler und Entwicklerinnen müssen die Konfigurationsoptionen innerhalb der Software verfolgen, um festzustellen,
welche Codefragmente von einer Option betroffen sind und wo und wie sie mit ihr interagieren.
Solche Fehler können dazu führen, dass die Software abstürzt, eine fehlerhafte Ausgabe erzeugt oder nur unzureichend funktioniert \cite[]{10.1145/2568225.2568251}.
Konfigurationsfehler entstehen zum Beispiel durch die Verwendung unterschiedlicher Versionen einer Software.
Im Listing \ref{logreg} wird die Klasse \textit{LogisticRegression} der Machine Learning-Bibliothek scikit-learn initialisiert
und der Variable \textit{clf} zugewiesen.

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}[language=Python, frame=single, label = logreg, basicstyle=\small, caption={Nutzung der LogisticRegression-Klasse aus scikit-learn},captionpos=b]
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression()
\end{lstlisting}
\end{minipage}
\

\noindent Da keine Parameter angegeben werden, wird die Klasse mit den Default-Werten initialisiert, zum Beispiel
\textit{max\_iter = 100, verbose = 0, n\_jobs = 1}.
Über den Parameter \textit{max\_iter} können beispielsweise die Anzahl der Trainingsiterationen
der Logistischen Regression festgelegt werden und über \textit{n\_jobs} die maximale Anzahl der parallel zu verwendenden CPU-Kernen.
In der Version 0.21.3 on scikit-learn wird für den Parameter \textit{multi\_class} als Default noch der Wert \textit{ovr} zugewiesen.
Für alle nachfolgenden Versionen ist der Default-Wert für diesen Parameter jedoch \textit{auto} \cite[]{sklearn}.
Folglich führt die Verwendung dieser Klasse ohne explizite Parameterangabe, nach Verwendung unterschiedlicher Versionen, zu schwer nachvollziehbaren Programmverhalten.