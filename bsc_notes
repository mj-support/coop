Notizen:

1. Zunächst einmal stellte sich die Herausforderungen, alle Module eines Frameworks zu erfassen. Gängige Python-Methoden geben zwar die Submodule aus, aber um sämtliche Konfiguratonsoptionen zu finden, müssen die auch noch durchlaufen werden. Hier war die Schwierigkeit einen Überblick zu behalten, da manche Methoden direkt aurufbar waren bspw. mflow.get_tracking_uri, die jedoch über den Pfad.
2. Rausgefiltert werden dabei Methods mit single leading underscore _ (Name ist nur für interne Zwecke) und double leading underscore __ (wird genamemangled also textuell mit etwas anderem ersetzt) siehe https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-single-and-double-underscore-before-an-object-name
3. Problematisch sind ebenfalls die Dopplungen von Namen, so befindet sich bspw.
	get_tracking_uri in mlflow und in mlflow.tracking
	log_artifact in mlflow und mlflow.tracking.MlflowClient
4. offen ist zudem wie die Config Optionen aus 3. in den echten Projekten dann auch getracket werden sollen. Möglichkeit: import mlflow und from mlflow Zeile untersuchen und dies zum Standard der Suche machen
5. Schwierigkeit zudem wie ich die Config-Options von normalen Methoden unterscheiden. list_artifacts ist vermutlich keine Configuration Option. 
6. Was ist zu dem mit den anderen dictioniairies etc.
7. Liste aller Methoden und Klassen mit for-Schleifen erwies sich als nicht zielführend, da Tiefe der for-Schleifen unbekannt -> Lösung: Baumstruktur mit Rekursion
8. Problem: Methoden können auf mehreren Wegen erreicht werden z.B. mlflow.h2o.mlflow.h2o.mlflow -> Gefahr von endlosen Schleifen / Rekursion
    Lösung: bei jedem Element wird geprüft ob es schon bereits im Baum vorhanden ist -> Verhindert Dopplungen, jedoch sind die Elemente dann an "falschen" Zweigen zugeordnet


types:
- module
- type
- method
- property
- builtin_function_or_method
- NoneType
- function
- str
- int
- string._TemplateMetaclass
- logging._StderrHandler
- bool
- logging.RootLogger
- urllib3.util.retry._RetryMeta
- typing._GenericAlias
- dict
- re.Pattern
- method_descriptor
- float
- getset_descriptor
- method_descriptor
- yaml.YAMLObjectMetaclass
- list

- Lösung:
    Doku der Packages werden auf der Website durchsucht. Dafür wird beautfilsoup als Scraper verwendet.
    Das ganze wird an PyTorch getestet. Dabei werden zunächst die ganzen Links der einzelnen Module gescrapt.
    In einer for-Schleife werden diese Links durchlaufen und in einem nested Dictionairy gespeichert mit dem Aufbau (module, (Function, Beschreibung))
    Vorteil ist das man auf Basis der Beschreibungen der Funktion sehr gut erkennen kann, welche Funktionen was machen. Beschreibungen die mit "Return" oder "" anfangen, kann man direkt aussortieren, Beschreibungen die mit Set anfangen sind potentielle Optionen.
    PRoblem: Die Beschreibungen werden tabellarisch in der Doku gespeichert. Leider sind nicht alle Seiten gleich aufgebaut, sodass bei einigen Modulen nichts gefunden wird oder die falsche Tabelle ausgelesen wird. Das muss händisch noch überprüft werden

- Neuer Ansatz: einfach dir() über Torch laufen lassen. Damit kann alles was über torch. aufgerufen wird angezeigt werden.


- Statische Code Analyse (https://luminousmen.com/post/python-static-analysis-tools)

- Zu Berücksichtigen:
    - Kommentare mit # oder "" ausschließen!
    - mehrere Zeilen zurückgeben, wenn über mehrere Zeilen verläuft
    - import Zeile besondere Aufmerksamkeit schenken. Mögliche Fälle: 1. import tensorflow 2. import tensorflow as tf 3. from tensorflow import xx
        1. Fall - Möglichkeiten:
            import tensorflow
            import tensorflow as tf
            import tensorflow, xx
            import tensorflow as tf, xx
            import xx, tensorflow
            import xx, tensorflow as tf
            import xx, tensorflow, yy
            import xx, tensorflow as tf, yy
            Lösung: unterteilen in mehrere Strings: import rauscutten
            UPDATE: 1. Fall: Falls Klassen definiert werden, an dieser Stelle direkt rausfiltern
            UPDATE: sklearn.base enthält as deshalb ändern
            evtl. Test mit allen möglichen Konstellationen schreiben?!

- UPDATE: nur noch Klassen rausfiltern. Klassen werden groß geschrieben, und von den Klassen nur noch die Parameter
        möglich Parameter kann man mit clf.__dict__ ausgeben, wenn man die Attribute, die mit _ enden noch löscht

- search_words ausdünnen, damit nicht jedes Mal eine spezifische Methode gesucht wird -> direkt eliminieren?

- Problem from sklearn import Class123 as c
    -> wie kann man nun nach c schauen?
Möglichkeiten wie Klassen auftachen:
    1. (Klasse,
    1. (Klasse)
    1. (Klasse
    1. (Klasse(
    1. (Klasse.
    2. ,Klasse)
    2. ,Klasse
    2. ,Klasse(
    2. ,Klasse,
    2. ,Klasse.
    3.  Klasse
    3.  Klasse(
    3.  Klasse,
    3.  Klasse)
    3.  Klasse.
    4. .Klasse(
    4. .Klasse)
    4. .Klasse,
    4. .Klasse
    4. .Klasse.


https://stackoverflow.com/questions/33506902/python-extracting-editing-all-constants-involved-in-a-function-via-ast

ungeklärte Probleme:
    - was wenn sich Wert einer Variable ändert bspw. am Anfang a = 5, am Ende a = 10, ausgegeben wird nur a = 10

zutun:
    - BinOp und UnaryOp immer checken!!!
    - Listen können unendlich tief sein -> auch das abdecken!

Fragen:
    - sklearn.cluster.AffinityPropagation() irrelevant?
    - ap = sklearn.cluster.AffinityPropagation() relevant?
    - linear_model.LinearRegression(2, 5) --> was davon relevant
    - regr = linear_model.LinearRegression(2, 5)
    - regr.fit(diabetes_X_train, diabetes_y_train)

- Ursprünglich alles als Dicitionary gespeichert, jedoch alphabetische Sortierung und keys einmalig, daher Lieber Liste
- Problem: unterscheiden zwischen strings und variable: plt.scatter(diabetes_X_test, diabetes_y_test, color=black)

Relevant:
    - linear_model.LinearRegression(6, 10)
    - regr = linear_model.LinearRegression(2, 5)
    - mdl.append(SVC(class_weight=None, probability=True))

irrelevant:
    - regr.fit(diabetes_X_train, diabetes_y_train)
    - regr2 = regr

Offen:
    - def func1():
        count = 100
        return count

      count = func1()
      linear_model.LinearRegression(count)
    - Welche Datenstruktur?
    - Wie berücksichtige ich die Struktur?
        - if/else, for
        - with
        - Funktionen
        - Klassen

große Frage: wie mit Klassen und Funktionen umgehen?

To Do: Umgang mit Kontrollstrukturen if, else, for

Möglichkeit string in strings darzustellen:
    model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

limit: Klammern beim bin.op werden nicht mit übernommen bsp. accum = accum * rho + (grad**2) * (1 - rho)

Konsitenz reinbringen bei den Kontrollstrukturen: for, while wird gedruckt, if else nicht?!, try/except auch nicht?
    Mögliche Lösung: Zeilenangaben anhängen und zuordnen

line no function definitions


Struktur:
    1. Werte aus Import-Lines filtern
    2. Durch ast-Objekte iterieren und Objekte rauslesen, die Import-Werte enthalten
        Problem: bspw. Function, Class, For etc haben bodys und kapseln oft selbst nochmal eine Vielzahl an Objekten
        Loopen durch:
            FunctionDef body, decorater_list (unnötig)
            AsyncFunctionDef body, decorater_list (unnötig)
            ClassDef bases, keywords, body, decorater_list
            Delete targets
            Assign targets
            For body, orelse
            AsyncFor body, orelse
            While body, orelse
            If body, orelse
            With items, body
            Async With items, body
            Match cases
            Try body, handlers, orelse, finalbody
            Import names
            ImportFrom names
            Global names
            Nonlocal names

            BoolOp values
            Dict keys
            Set elts
            ListComp generators
            SetComp generators
            DictComp generators
            GeneratorExp generators
            Compare ops, comparators
            Call args, keywords
            JoinedStr values
            List elts
            Tuple elts

            comprehension ifs
            excepthandler ExceptHandler:body
            arguments posonlyargs, args, kwonlyargs, kw_defaults, defaults
            match_case body
            pattern


            Lösung: Typ prüfen und rausfiltern

            body: FunctionDef, AsyncFunctionDef, ClassDef, For, AsyncFor, While, If, With, AsyncWith, Try
            ?decorator_list: FunctionDef, AsyncFunctionDef, ClassDef
            orelse: For, AsyncFor, While, If, Try
            handlers: Try -> [excepthandler1: body] #Try hat handlers, handlers ist Liste aus mehrern ExceptHandlers, jeder ExceptHandler hat Body
            finalbody: Try

            Offen: Match

            3 Categorien:
            FunctionDef, AsyncFunctionDef, ClassDef, With, AsyncWith, ExceptHandler: body
            For, AsyncFor, While, If: body, orelse
            Try: body, orelse, handlers, finalbody


        Vorgehen:
            1. alle Objekte finden, in den relevante import-values auftauchen
            2. durch einzelene Objekte nach den 3 oberen Kategorieren iterieren
            3. gucken ob bei den import-values auch Klassen dabei sind (Vergleich mit scraper) attr =, id =


        category1 = [ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.With, ast.AsyncWith, ast.ExceptHandler]
category2 = [ast.For, ast.AsyncFor, ast.While, ast.If]
category3 = [ast.Import, ast.ImportFrom]

Frage: Wie umgehen wenn var = blabla + bla(LogisticRegression(x=1). Stand jetzt ist Var die Variable
umgang mit +=

code': "cross_val_predict(cv=KFold(2))"  -> Variable -> cv
code': 'kernels = [RBF(length_scale=0.1), fixed_kernel, '
            'RBF(length_scale=1.0, length_scale_bounds=(0.001, 1000.0)), '
            'C(1.0, (0.01, 100.0)) * RBF(length_scale=1.0, '
            'length_scale_bounds=(0.001, 1000.0))]'  -> Lösungen für mehrmals RBF?
kernels = [
    RBF(length_scale=2.0),
    RBF(length_scale_bounds=(0.5, 2.0)),
    ConstantKernel(constant_value=10.0),
    2.0 * RBF(length_scale=0.33, length_scale_bounds="fixed"),
    2.0 * RBF(length_scale=0.5),
    kernel_rbf_plus_white,
    2.0 * RBF(length_scale=[0.5, 2.0]),
    2.0 * Matern(length_scale=0.33, length_scale_bounds="fixed"),
    2.0 * Matern(length_scale=0.5, nu=0.5),
    2.0 * Matern(length_scale=1.5, nu=1.5),
    2.0 * Matern(length_scale=2.5, nu=2.5),
    2.0 * Matern(length_scale=[0.5, 2.0], nu=0.5),
    3.0 * Matern(length_scale=[2.0, 0.5], nu=1.5),
    4.0 * Matern(length_scale=[0.5, 0.5], nu=2.5),
    RationalQuadratic(length_scale=0.5, alpha=1.5),
    ExpSineSquared(length_scale=0.5, periodicity=1.5),
    DotProduct(sigma_0=2.0),
    DotProduct(sigma_0=2.0) ** 2,
    RBF(length_scale=[2.0]),
    Matern(length_scale=[2.0]),
]

Zu beachten: Dummys, Variablenzuweisung, AugAssing etc, decorators, Dopplungen

Speicherung in Tupel, da Dict sortiert sind

Zuweisung der Parameter zu den Klassen:
class sklearn.decomposition.SparseCoder(dictionary, *, transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, split_sign=False, n_jobs=None, positive_code=False, transform_max_iter=1000)
alles was nach Sternchen kommt, muss mit Parameternamen angegeben werden
nur dictionary darf direkt mit einem Wert initialisiert werden
https://stackoverflow.com/questions/66922295/what-does-asterisk-mean-when-used-as-a-param-for-a-scikit-learn-model


(cfgnet-XNQxSlNA-py3.8) marco@Marcos-MacBook-Pro CfgNet % poetry run cfgnet export --output=export2 --format=png --include-unlinked --visualize-dot /Users/marco/repos/CfgNet

Scalpel wird nicht verwendet, da unter anderem Verarbeitung von Dictionairies nicht funktioniert. Bsp. x = test_dict["key"] läuft in Exception und führt zu Abbruch

Mögliches Vorgehen zum Tracking der Variablenwerte:
    1. Alle Variablenzuweisungen der Funktion rausfiltern
    2. Objekte nach gesuchten Variable durchsuchen

Zu Tun:
- Variablenwerte tracken
- Parameter im Fall von Dopplungen behandeln! -> DONE!!

Zu Variablenwerte tracken:
    1) Prüfen ob es sich um Variablen oder Konstanten handelt
    2) Wenn Variable(n), dann Übergeordnete Funktionen und Klassen betrachten:
        3) Alle oberen Zuweisungen rausfiltern
        4) Prüfen, welche Zuweisungen der(den) gesuchten Variable(n) Werte zuweisen
    -> Scope bleibt aber immer nur die übergeordnete Funktion / Klasse!

src  -> plugins -> source_code
-> modules: json file hinzufügen
-> von sklearn plug_in code mehr oder weniger kopieren bzw. die ersten beiden Funktionen der Klasse (is_responsible, parse_config_file
test -> files -> datei hinzufügen für pytorch zum testen

es muss ein git repository sein!
immer erst option zum artifact hinzufügen
artifact ist .py datei
plugin manager zeile 27, 47 adaptieren
unter plugin_manager bei source_code Plugins hinzuüfgen

diese beiden Befehle ausführen - .py datei in test/files ordner hinzufügen
poetry run cfgnet init /Users/marco/repos/CfgNet
poetry run cfgnet export --output=graph_test --format=png --include-unlinked --visualize-dot /Users/marco/repos/CfgNet



Scope fürs Variablentracking:
    - alle Assignments auf erster Ebene
        - dafür in obj_selector: alle Funktionen finden.














